{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996e3ff9-d200-44bc-ad89-6764c9f581dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a4a961-e58b-4845-95da-cb8c4d87466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea5d8c7-6908-430a-999b-f001ce80a19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "#import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, Lipinski, PandasTools\n",
    "\n",
    "from kinfraglib import utils\n",
    "from kinfraglib import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a49a85-ba94-45c6-b3ff-47499ea40686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to display ROMol images in DataFrames\n",
    "PandasTools.RenderImagesInAllDataFrames(images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1955894-4046-4766-90dc-30f67874598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data\n",
    "HERE = Path(_dh[-1])\n",
    "PATH_DATA = HERE / '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb88c575-6f19-4711-9262-32cd72ad78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_library = utils.read_fragment_library(PATH_DATA / 'fragment_library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289e8c25-dfe4-48d5-a26b-a0783918754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_library = filters.prefilters.pre_filters(\n",
    "    fragment_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edb6518-2204-4499-8d92-edbd9b07cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pains_dict = filters.pains.get_pains(fragment_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12d62a4-8787-4d39-8683-c046f3931374",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_library = pains_dict[\"fragment_library\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b8ae72f-4988-47da-bc7a-51dbf94b8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = Path(_dh[-1])\n",
    "DATA =  HERE / '../../../Brenk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c483ab62-182f-430a-9958-a292ce869f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unwanted substructures in Brenk et al. collection: 104\n"
     ]
    }
   ],
   "source": [
    "brenk_dict = filters.unwanted_substructures.get_brenk(fragment_library, DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49b4f43e-aae3-45af-8be8-c6a3d97b966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_library =  brenk_dict['fragment_library']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25084a6d-e7a4-49b5-b7b1-41da32e3ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "druglikeness_dict = filters.ruleofthree.get_ro3_frags(fragment_library)\n",
    "fragment_library = druglikeness_dict[\"fragment_library\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558b1a2c-3b58-4908-a86e-41e58cc53e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_qed = filters.qed.get_qed(fragment_library)\n",
    "fragment_library = res_qed[\"fragment_library\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dbe0004-d7fd-4aa6-b6e5-9d8ca79dda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizability_dict = filters.building_blocks.check_building_blocks(\n",
    "    fragment_library,\n",
    "    str(str(PATH_DATA)+'/filters/DataWarrior/Enamine_Building_Blocks.sdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d24655e6-7558-44a9-8773-4f5d9915b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_library = synthesizability_dict['fragment_library']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00110398-78e0-49a5-8010-cb38ce5e890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sybas = filters.syba.calc_syba(\n",
    "    fragment_library,\n",
    "    cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c3c1e33-c2b2-43f4-b6b7-28e12bcb7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_library = d_sybas['fragment_library']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a109b306-c594-4977-908a-86368789f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_library = filters.analysis.number_of_accepted(\n",
    "    fragment_library, columns=['bool_pains', 'bool_brenk', 'ro3', 'qed', 'bool_bb', 'bool_syba'],\n",
    "    min_accepted=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2137e802-2547-45d6-9dfc-826a7dda08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subpocket in fragment_library.keys():\n",
    "    fragment_library[subpocket].drop(fragment_library[subpocket].loc[fragment_library[subpocket]['bool']==0].index, inplace=True)\n",
    "    fragment_library[subpocket] = fragment_library[subpocket].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b7e459a-85d0-469d-99a0-5fe4745effaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuple(fragment, dummy_atoms):\n",
    "\n",
    "    \"\"\"\n",
    "    **copied from https://github.com/volkamerlab/KinaseFocusedFragmentLibrary/blob/b7e684c26f75efffc2a9ba2383c9027cdd4c29a3/kinase_focused_fragment_library/recombination/classes_meta.py**  # noqa: E501\n",
    "    For a given fragment, returns:\n",
    "    - smiles string with generic dummy atoms (dummy labels removed)\n",
    "    - dummy atoms as tuples of frag_atom_id and subpocket (of the dummy = neighboring subpocket of\n",
    "    the fragment)\n",
    "    Parameters\n",
    "    ----------\n",
    "    fragment: RDKit Mol object\n",
    "    dummy_atoms: list(RDKit Atom objects)\n",
    "        list of all dummy atoms of the fragment\n",
    "    Returns\n",
    "    -------\n",
    "    String\n",
    "        SMILES string of the fragment\n",
    "    frozenset(tuple)\n",
    "        frozenset of tuples for each dummy atom containing the frag_atom_id and the subpocket of\n",
    "        the dummy\n",
    "    \"\"\"\n",
    "\n",
    "    frag_smiles = fragment\n",
    "    # replace dummys with generic dummys (without atom number)\n",
    "    # dummy tuple: (frag_atom_id, neighboring_subpocket), e.g. (AP_4, FP)\n",
    "    dummy_set = []\n",
    "    for dummy in dummy_atoms:\n",
    "        frag_smiles = Chem.ReplaceSubstructs(\n",
    "            frag_smiles, Chem.MolFromSmiles(dummy.GetSmarts()), Chem.MolFromSmiles(\"*\")\n",
    "        )[0]\n",
    "        dummy_tuple = dummy.GetProp(\"frag_atom_id\"), dummy.GetProp(\"subpocket\")\n",
    "        dummy_set.append(dummy_tuple)\n",
    "    frag_smiles = Chem.MolToSmiles(frag_smiles)\n",
    "\n",
    "    dummy_set = frozenset(dummy_set)\n",
    "\n",
    "    return frag_smiles, dummy_set\n",
    "\n",
    "\n",
    "class Compound:\n",
    "\n",
    "    \"\"\"\n",
    "    **copied from https://github.com/volkamerlab/KinaseFocusedFragmentLibrary/blob/b7e684c26f75efffc2a9ba2383c9027cdd4c29a3/kinase_focused_fragment_library/recombination/classes_meta.py**  # noqa: E501\n",
    "    Represents a combination of fragments including its dummy atoms\n",
    "    Attributes\n",
    "    ----------\n",
    "    frag_ids: list(str)\n",
    "        Strings representing the fragments that the molecule consists of\n",
    "    subpockets: list(str)\n",
    "        Subpockets that the molecule is targeting\n",
    "    ports: list(Port)\n",
    "        Port objects representing the dummy atoms of the molecule\n",
    "    bonds: list(tuple(str))\n",
    "        Bonds through which the fragments are connected.\n",
    "        The bonds are stored as tuples of atom IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frag_ids, subpockets, ports, bonds):\n",
    "\n",
    "        self.frag_ids = frag_ids\n",
    "        self.subpockets = subpockets\n",
    "        self.ports = ports\n",
    "        self.bonds = bonds\n",
    "\n",
    "\n",
    "class Fragment:\n",
    "\n",
    "    \"\"\"\n",
    "    **copied from https://github.com/volkamerlab/KinaseFocusedFragmentLibrary/blob/b7e684c26f75efffc2a9ba2383c9027cdd4c29a3/kinase_focused_fragment_library/recombination/classes_meta.py**  # noqa: E501\n",
    "    Represents a single fragment from the fragment library\n",
    "    Attributes\n",
    "    ----------\n",
    "    frag_id: str\n",
    "        ID of the fragment: subpocket_ID, e.g. AP_5\n",
    "    subpocket: str\n",
    "        Subpocket that the fragment is targeting\n",
    "    ports: list(Port)\n",
    "        Port objects representing the dummy atoms of the fragment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frag_id, subpocket, ports):\n",
    "\n",
    "        self.frag_id = frag_id\n",
    "        self.subpocket = subpocket  # list of targeted subpockets\n",
    "        self.ports = ports  # list of Port objects\n",
    "\n",
    "\n",
    "class Port:\n",
    "\n",
    "    \"\"\"\n",
    "    **copied from https://github.com/volkamerlab/KinaseFocusedFragmentLibrary/blob/b7e684c26f75efffc2a9ba2383c9027cdd4c29a3/kinase_focused_fragment_library/recombination/classes_meta.py**  # noqa: E501\n",
    "    Represents a single dummy atom\n",
    "    Attributes\n",
    "    ----------\n",
    "    atom_id: str\n",
    "        frag_atom_id of the dummy atom\n",
    "    subpocket: str\n",
    "        Subpocket of the atom adjacent to the dummy atom (subpocket of the fragment containing\n",
    "        the dummy)\n",
    "    neighboring_subpocket: str\n",
    "        Subpocket of the dummy atom\n",
    "    bond_type: str\n",
    "        Type of the bond connecting the dummy to its adjacent atom\n",
    "    environment: str\n",
    "        Type of the environment of the current fragment (of the adjacent atom)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, atom_id, subpocket, neighboring_subpocket, bond_type, environment\n",
    "    ):\n",
    "\n",
    "        self.atom_id = atom_id\n",
    "        self.subpocket = subpocket\n",
    "        self.neighboring_subpocket = neighboring_subpocket\n",
    "        self.bond_type = bond_type\n",
    "        self.environment = environment\n",
    "\n",
    "\n",
    "class Combination:\n",
    "\n",
    "    \"\"\"\n",
    "    **copied from https://github.com/volkamerlab/KinaseFocusedFragmentLibrary/blob/b7e684c26f75efffc2a9ba2383c9027cdd4c29a3/kinase_focused_fragment_library/recombination/classes_meta.py**  # noqa: E501\n",
    "    Comparable representation of a combination of fragments\n",
    "    Attributes\n",
    "    ----------\n",
    "    frag_ids: frozenset(str)\n",
    "        Strings representing the fragments that the molecule consists of\n",
    "    bonds: frozenset(tuple(str))\n",
    "        Bonds through which the fragments are connected.\n",
    "        The bonds are stored as tuples of atom IDs.\n",
    "    Methods\n",
    "    ----------\n",
    "    __eq__()\n",
    "        Two Combination objects are equal if they consist of the same fragments which are\n",
    "        connected through the same bonds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frag_ids, bonds=None):\n",
    "        self.frag_ids = frag_ids\n",
    "        self.bonds = bonds\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.frag_ids == other.frag_ids and self.bonds == other.bonds\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.frag_ids, self.bonds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b05779-8388-4448-b75e-d4b92d52226a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa9cee70-5373-464c-a213-3b1e0391c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_pairs(fragment_library):\n",
    "    \"\"\"\n",
    "        *copied and adapted from kinase_focused_fragment_library*\n",
    "    \"\"\"\n",
    "    data = {}  # (Fragments)\n",
    "    frag_set = set()  # only used in initialization for avoiding duplicates in fragment data set (smiles & dummy atoms)\n",
    "\n",
    "    #iterate through subpockets and fragments in subpockets\n",
    "    #save subpocket_fragmentindex and dummy atoms, bonds etc\n",
    "    for subpocket in fragment_library.keys():\n",
    "        fragments = []\n",
    "        for i, row in fragment_library[subpocket].iterrows():\n",
    "            #get fragment and connecting subpockets\n",
    "            fragment = row['ROMol_original']\n",
    "            fragment = Chem.RemoveHs(fragment)\n",
    "            frag_id = f'{subpocket}_{i}'\n",
    "            \n",
    "            # store unique atom identifiers\n",
    "            for a, atom in enumerate(fragment.GetAtoms()):\n",
    "                frag_atom_id = f'{subpocket}_{a}'\n",
    "                atom.SetProp('frag_atom_id', frag_atom_id)\n",
    "                \n",
    "            # get all dummy atoms of this fragment except the ones corresponding to the X pool\n",
    "            dummy_atoms = [a for a in fragment.GetAtoms() if a.GetSymbol() == '*' and not a.GetProp('subpocket').startswith('X')]\n",
    "            if not dummy_atoms:\n",
    "                continue\n",
    "            \n",
    "            frag_smiles, dummy_set = get_tuple(fragment, dummy_atoms)\n",
    "            # check if this exact fragment has already been found\n",
    "            if (frag_smiles, dummy_set) in frag_set:\n",
    "                continue\n",
    "            # if not, add this fragment to set of fragments\n",
    "            frag_set.add((frag_smiles, dummy_set))\n",
    "\n",
    "            # create dummy atom objects\n",
    "            ports = [Port(atom_id=dummy.GetProp('frag_atom_id'), subpocket=subpocket, neighboring_subpocket=dummy.GetProp('subpocket'),\n",
    "                          bond_type=fragment.GetBondBetweenAtoms(dummy.GetIdx(), dummy.GetNeighbors()[0].GetIdx()).GetBondType(),\n",
    "                          environment=dummy.GetNeighbors()[0].GetProp('environment'))\n",
    "                     for dummy in dummy_atoms]   \n",
    "            # add all dummy atoms of this fragment to the queue\n",
    "            #compound = Compound(frag_ids=[frag_id], subpockets=[subpocket], ports=ports, bonds=[])\n",
    "            #combo = Combination(frag_ids=frozenset([frag_id]))\n",
    "            \n",
    "            # store fragment in constant data set\n",
    "            fragment = Fragment(frag_id=frag_id, subpocket=subpocket, ports=ports)\n",
    "            fragments.append(fragment)\n",
    "        data[subpocket] = fragments\n",
    "        \n",
    "    n_frags = len(frag_set)\n",
    "\n",
    "    print('Number of fragments: ', n_frags)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a66c25c-3449-4bfa-be0a-b81223cd9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkvalid(data, fragment_library):\n",
    "    matches = [] #save matching fragment pairs\n",
    "    #iterate through subpockets\n",
    "    for subpocket in fragment_library.keys():\n",
    "        #iterate through fragments in subpockets\n",
    "        for fragment in data[subpocket]:\n",
    "            fragment_id1 = fragment.frag_id #store fragment ID of first fragment in pair\n",
    "            #go through atom connnections and check neighbors, bond type and environment\n",
    "            for i in range(0,len(fragment.ports)):\n",
    "                neighbor = fragment.ports[i].neighboring_subpocket\n",
    "                bond_type = fragment.ports[i].bond_type\n",
    "                environment = fragment.ports[i].environment\n",
    "                match = [] #store current matching fragment pair\n",
    "                for frag2 in data[neighbor]:\n",
    "                    fragment_id2 = frag2.frag_id  #store fragment ID of second fragment            \n",
    "                    for i in range(0,len(frag2.ports)): \n",
    "                        #check environment type, subpocket, bond type\n",
    "                        environment_match = filters.brics_rules.is_brics_bond(environment, frag2.ports[i].environment) #check if BRICS environments are able to form connection\n",
    "                        #if subpocket is adjacent, bond type is eqal and environments are matching, add as valid matching pair\n",
    "                        if frag2.ports[i].neighboring_subpocket == subpocket and neighbor ==  frag2.ports[i].subpocket and frag2.ports[i].bond_type == bond_type and environment_match:\n",
    "                            match.append([fragment_id1, fragment_id2])        \n",
    "                matches.append(match) #add valid matching pair to list of matching pairs\n",
    "    return matches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c080a60-5319-4994-bc87-2cd2c7566b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fragments:  487\n"
     ]
    }
   ],
   "source": [
    "res = get_valid_pairs(fragment_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17a4075a-8664-4559-a96b-ff40dc4969e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids = checkvalid(res, fragment_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d45a848c-a225-4068-b999-635a4ccc3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bonds(valids, data, fragment_library):\n",
    "    bonds = [] #store bonds of valid matching pairs as atom IDs where connection is formed\n",
    "    #go through all valid pairs\n",
    "    for valid in valids:\n",
    "        bond = []\n",
    "        for val in valid:\n",
    "            #load fragments that should get connected\n",
    "            subpocket1 = val[0].split(\"_\")[0]\n",
    "            fragment1_index = int(val[0].split(\"_\")[1])\n",
    "            fragment1 = fragment_library[subpocket1][\"ROMol_original\"][fragment1_index] \n",
    "            #remove Hs before finding bonds otherwise bond ids not correct because for combining molecules without Hs are used\n",
    "            fragment1 = Chem.RemoveHs(fragment1)\n",
    "            \n",
    "            subpocket2 = val[1].split(\"_\")[0]\n",
    "            fragment2_index = int(val[1].split(\"_\")[1])\n",
    "            fragment2 = fragment_library[subpocket2][\"ROMol_original\"][fragment2_index] \n",
    "            #remove Hs before finding bonds\n",
    "            fragment2 = Chem.RemoveHs(fragment2)\n",
    "            \n",
    "            #i = 0\n",
    "            bond1_id = None\n",
    "            bond2_id = None\n",
    "        \n",
    "            \n",
    "            data1 = data[subpocket1][fragment1_index] #get corresponding connection to load environment, bond type and neighboring subpocket\n",
    "            for i in range(0,len(data1.ports)):\n",
    "                environment1 = data1.ports[i].environment\n",
    "                bond_type1 = data1.ports[i].bond_type\n",
    "                neighbor1 = data1.ports[i].neighboring_subpocket\n",
    "                \n",
    "                data2 = data[subpocket2][fragment2_index] #for matching fragment also get the connection data\n",
    "                for j in range(0,len(data2.ports)):\n",
    "                    environment2 = data2.ports[j].environment\n",
    "                    bond_type2 = data2.ports[j].bond_type\n",
    "                    neighbor2 = data2.ports[j].neighboring_subpocket\n",
    "                    \n",
    "                    #check again if BRICS bond, bond types and subpockets are matching for a connection\n",
    "                    if  filters.brics_rules.is_brics_bond(environment1, environment2) and bond_type1 == bond_type2 and subpocket2 == neighbor1 and subpocket1 == neighbor2:\n",
    "                        #get atom indices where connection is build\n",
    "                        for atom in fragment1.GetAtoms():\n",
    "                            atom_symbol = atom.GetSymbol()\n",
    "                            if atom_symbol == \"*\":\n",
    "                                bond1_id = subpocket1 + \"_\" + str(atom.GetIdx())\n",
    "                        \n",
    "                        for atom2 in fragment2.GetAtoms():\n",
    "                            atom_symbol2 = atom2.GetSymbol()\n",
    "                            if atom_symbol2 == \"*\":\n",
    "                                bond2_id = subpocket2 + \"_\" + str(atom2.GetIdx())\n",
    "                        \n",
    "            bond.append([bond1_id, bond2_id, bond_type1]) #save atom indices and bond type for building the connection\n",
    "        bonds.append(bond)\n",
    "    return bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cffb5108-8232-45cf-bb5d-1a6693a1b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds = get_bonds(valids, res, fragment_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a663fe2-dddb-461d-a303-7f01f77a182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_ligand(fragment_ids, bond_ids, fragment_library):\n",
    "    \"\"\"\n",
    "    *copied and adapted from kinase_focused_fragment_library*\n",
    "    Construct a ligand by connecting multiple fragments based on a Combination object\n",
    "    Parameters\n",
    "    ----------\n",
    "    fragment_ids: list of str\n",
    "        Fragment IDs of recombined ligand, e.g. `[\"SE_2\", \"AP_0\", \"FP_2\"]` (`<subpocket>_<fragment index in subpocket pool>`).\n",
    "    bond_ids : list of list of str\n",
    "        Bond IDs of recombined ligand, e.g. `[[\"FP_6\", \"AP_10\"], [\"AP_11\", \"SE_13\"]]`: Atom (`<subpocket>_<atom ID>`) pairs per fragment bond.\n",
    "    fragment_library : dict of pandas.DataFrame\n",
    "        SMILES and RDKit molecules for fragments (values) per subpocket (key).\n",
    "    Returns\n",
    "    -------\n",
    "    ligand: rdkit.Chem.rdchem.Mol or None\n",
    "        Recombined ligand (or None if the ligand could not be constructed)\n",
    "    \"\"\"\n",
    "\n",
    "    fragments = []\n",
    "    for fragment_id in fragment_ids:\n",
    "\n",
    "        # Get subpocket and fragment index in subpocket\n",
    "        subpocket = fragment_id.split(\"_\")[0]\n",
    "        fragment_index = int(fragment_id.split(\"_\")[1])\n",
    "        fragment = fragment_library[subpocket].ROMol_original[fragment_index]\n",
    "\n",
    "        # Store unique atom identifiers in original molecule (important for recombined ligand construction based on atom IDs)\n",
    "        fragment = Chem.RemoveHs(fragment)\n",
    "        for i, atom in enumerate(fragment.GetAtoms()):\n",
    "            fragment_atom_id = f\"{subpocket}_{i}\"\n",
    "            atom.SetProp(\"fragment_atom_id\", fragment_atom_id)\n",
    "            atom.SetProp(\"fragment_id\", fragment.GetProp(\"complex_pdb\"))\n",
    "        fragment = PropertyMol(fragment)\n",
    "\n",
    "        # Append fragment to list of fragments\n",
    "        fragments.append(fragment)\n",
    "\n",
    "    # Combine fragments using map-reduce model\n",
    "    combo = reduce(Chem.CombineMols, fragments)\n",
    "\n",
    "    bonds_matching = True\n",
    "    ed_combo = Chem.EditableMol(combo)\n",
    "    replaced_dummies = []\n",
    "\n",
    "    #atoms = combo.GetAtoms()\n",
    "    \n",
    "    \n",
    "    #for bond in bond_ids:\n",
    "\n",
    "    dummy_1 = next(\n",
    "            atom for atom in combo.GetAtoms() if atom.GetProp(\"fragment_atom_id\") == bond_ids[0]\n",
    "    )\n",
    "    dummy_2 = next(\n",
    "            atom for atom in combo.GetAtoms() if atom.GetProp(\"fragment_atom_id\") == bond_ids[1]\n",
    "    )\n",
    "    atom_1 = dummy_1.GetNeighbors()[0]\n",
    "    atom_2 = dummy_2.GetNeighbors()[0]\n",
    "\n",
    "    # check bond types\n",
    "    bond_type_1 = combo.GetBondBetweenAtoms(dummy_1.GetIdx(), atom_1.GetIdx()).GetBondType()\n",
    "    bond_type_2 = combo.GetBondBetweenAtoms(dummy_2.GetIdx(), atom_2.GetIdx()).GetBondType()\n",
    "    if bond_type_1 != bond_type_2:\n",
    "        bonds_matching = False\n",
    "        print(\"Bonds not matching\")\n",
    "\n",
    "    ed_combo.AddBond(atom_1.GetIdx(), atom_2.GetIdx(), order=bond_type_1)\n",
    "\n",
    "    replaced_dummies.extend([dummy_1.GetIdx(), dummy_2.GetIdx()])\n",
    "\n",
    "    # Do not construct this ligand if bond types are not matching\n",
    "    if not bonds_matching:\n",
    "        return\n",
    "\n",
    "    # Remove replaced dummy atoms\n",
    "    replaced_dummies.sort(reverse=True)\n",
    "    for dummy in replaced_dummies:\n",
    "        ed_combo.RemoveAtom(dummy)\n",
    "\n",
    "    ligand = ed_combo.GetMol()\n",
    "\n",
    "    # Replace remaining dummy atoms with hydrogens\n",
    "    du = Chem.MolFromSmiles(\"*\")\n",
    "    h = Chem.MolFromSmiles(\"[H]\", sanitize=False)\n",
    "    ligand = AllChem.ReplaceSubstructs(ligand, du, h, replaceAll=True)[0]\n",
    "    try:\n",
    "        ligand = Chem.RemoveHs(ligand)\n",
    "    except ValueError:\n",
    "        print(Chem.MolToSmiles(ligand))\n",
    "        return\n",
    "\n",
    "    # Clear properties\n",
    "    for prop in ligand.GetPropNames():\n",
    "        ligand.ClearProp(prop)\n",
    "    for atom in ligand.GetAtoms():\n",
    "        atom.ClearProp(\"fragment_atom_id\")\n",
    "\n",
    "    # Generate 2D coordinates\n",
    "    AllChem.Compute2DCoords(ligand)\n",
    "\n",
    "    return ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "687184d5-c53a-4d85-8da8-933d3ab54f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(valids, bonds, fragment_library_filtered):\n",
    "    pairs = []\n",
    "    frags1 = []\n",
    "    frags2 = []\n",
    "    ids = []\n",
    "    for i in range(0, len(valids)):\n",
    "        for j in range(0, len(valids[i])):\n",
    "            frag1 = fragment_library_filtered[valids[i][j][0].split(\"_\")[0]]['ROMol_dummy'][int(valids[i][j][0].split(\"_\")[1])]\n",
    "            frag2 = fragment_library_filtered[valids[i][j][1].split(\"_\")[0]]['ROMol_dummy'][int(valids[i][j][1].split(\"_\")[1])]\n",
    "            \n",
    "            frags1.append(frag1)\n",
    "            frags2.append(frag2)\n",
    "            \n",
    "            pair = construct_ligand(valids[i][j], bonds[i][j], fragment_library_filtered)\n",
    "            pairs.append(pair)\n",
    "            ids.append(valids[i][j])\n",
    "            \n",
    "    return pd.DataFrame({'fragment ids': ids, 'fragment1':frags1, 'fragment2':frags2, 'pair':pairs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ff2d98d-7ea4-459a-aa66-6fe009a95c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.PropertyMol import PropertyMol\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac3fbb9b-645d-4de9-9642-153df791240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df = get_pairs(valids, bonds, fragment_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a00ace2-d2d4-443a-8654-d85d8c8f4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_smiles = []\n",
    "for pair in pair_df['pair']:\n",
    "    pair_smiles.append(Chem.MolToSmiles(pair))\n",
    "    \n",
    "unique_smiles = pd.DataFrame({'pair': pair_smiles})['pair'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1993b7-076b-44f6-b98f-21b470ca5beb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b671f5e-5d13-424b-bff2-49a0087381ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import warnings\n",
    "import redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47d576c1-303e-41f3-a35f-4a34a9794d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@redo.retriable(attempts=10, sleeptime=2)\n",
    "def call_retro_parallel(smile):\n",
    "    \"\"\"\n",
    "    One step retrosynthesis using ASKCOS for all valid build pairs of fragments.\n",
    "    Saving the plausibility and the children that can build this pair according to retrosynthetic\n",
    "    analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pair_smiles : numpy array\n",
    "        containing SMILES strings of pairs build by fragments\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas DataFrame\n",
    "        containing the pair, the children building this pair and their plausibility\n",
    "\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    children1 = []\n",
    "    children2 = []\n",
    "    plausibilities = []\n",
    "    # n_attempts = 5\n",
    "    #print(smile)\n",
    "    pairs.append(smile)\n",
    "    cur_children1 = []\n",
    "    cur_children2 = []\n",
    "    cur_plausibilities = []\n",
    "    HOST = \"https://askcos.mit.edu/\"\n",
    "    params = {\n",
    "                \"smiles\": smile,  # required\n",
    "                # optional with defaults shown\n",
    "                \"max_depth\": 1,  # maximum number of reaction steps\n",
    "                \"max_branching\": 25,  # ?max number of branches are looked at to find \"best\"?\n",
    "                \"expansion_time\": 20,  # how long the expansion can run\n",
    "                \"max_ppg\": 100,  # maximum price per gram\n",
    "                \"template_count\": 100,\n",
    "                # \"max_cum_prob\"\n",
    "                # which common probability reached until no more templates are used\n",
    "                \"max_cum_prob\": 0.995,\n",
    "                # \"chemical_property_logic\"\n",
    "                # molecules are buyable or not, can be 'none' (only price relevant),\n",
    "                # 'and' (price and heavy atoms constraint) or\n",
    "                # 'or' (one of both constraints is relevant)\n",
    "                \"chemical_property_logic\": \"none\",\n",
    "                # max heavy atom contraints if 'and' or 'or' is used in 'chemical_property_logic'\n",
    "                \"max_chemprop_c\": 0,\n",
    "                \"max_chemprop_n\": 0,\n",
    "                \"max_chemprop_o\": 0,\n",
    "                \"max_chemprop_h\": 0,\n",
    "                # want to use popular chemicals as reasonable stopping points?\n",
    "                \"chemical_popularity_logic\": \"none\",\n",
    "                \"min_chempop_reactants\": 5,  # min frequence as popular reactant\n",
    "                \"min_chempop_products\": 5,  # min frequence as popular prouct\n",
    "                \"filter_threshold\": 0.75,\n",
    "                \"return_first\": \"true\",  # default is false\n",
    "    }\n",
    "            # for attempt in range(n_attempts):\n",
    "    # try:\n",
    "    resp = requests.get(HOST + \"/api/treebuilder/\", params=params,\n",
    "                                    verify=False)\n",
    "    # except requests.exceptions.Timeout as err:\n",
    "    #     print(err)\n",
    "    #     sleep(50)\n",
    "    #     continue\n",
    "    retro = resp.json()\n",
    "\n",
    "    if \"trees\" in retro:\n",
    "        if (len(retro[\"trees\"])) > 0:\n",
    "            for num_tree in range(0, len(retro[\"trees\"])):\n",
    "                if len(retro[\"trees\"][num_tree][\"children\"][0][\"children\"]) == 2:\n",
    "                    plausibility = retro[\"trees\"][0][\"children\"][0][\"plausibility\"]\n",
    "                    child1 = retro[\"trees\"][num_tree][\"children\"][0][\"children\"][0][\n",
    "                                \"smiles\"\n",
    "                    ]\n",
    "                    child2 = retro[\"trees\"][num_tree][\"children\"][0][\"children\"][1][\n",
    "                                \"smiles\"\n",
    "                    ]\n",
    "                    cur_children1.append(child1)\n",
    "                    cur_children2.append(child2)\n",
    "                    cur_plausibilities.append(plausibility)\n",
    "\n",
    "        else:\n",
    "            cur_children1.append(None)\n",
    "            cur_children2.append(None)\n",
    "            cur_plausibilities.append(0)\n",
    "    else:\n",
    "        cur_children1.append(None)\n",
    "        cur_children2.append(None)\n",
    "        cur_plausibilities.append(0)\n",
    "    children1.append(cur_children1)\n",
    "    children2.append(cur_children2)\n",
    "    plausibilities.append(cur_plausibilities)\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        list(zip(pairs, children1, children2, plausibilities)),\n",
    "        columns=[\"pair\", \"child 1\", \"child 2\", \"plausibility\"],\n",
    "    )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d24d927-61c3-4245-8769-c8af43eb8673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8873\n",
      "CPU times: user 11.3 s, sys: 2.78 s, total: 14.1 s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def worker(working_queue, output_queue):\n",
    "    while True:\n",
    "        if working_queue.empty() == True:\n",
    "            break #this is the so-called 'poison pill'    \n",
    "        else:\n",
    "            smiles = working_queue.get() #get smiles from working queue\n",
    "            res = call_retro_parallel(smiles)\n",
    "            #call askcos for one smiles\n",
    "            #then save result string to output_queue\n",
    "            for i, row in res.iterrows():\n",
    "                output_queue.put(str(row['pair']) + \"; \" + str(row['child 1']) + \"; \" + str(row['child 2']) + \"; \" + str(row['plausibility']) + \"\\n\")\n",
    "        if output_queue.qsize() > 100:\n",
    "            print(\"Size of output_queue > 100.\")\n",
    "            print(\"Writing output_queue to file..\")\n",
    "            with open(\"retro_tmp.txt\", \"a+\") as f_object:\n",
    "                while True:\n",
    "                    if output_q.empty() == True:\n",
    "                        break\n",
    "                    else:\n",
    "                        f_object.write(output_q.get_nowait())\n",
    "            f_object.close()\n",
    "    return\n",
    "\n",
    "filtered_smiles = []\n",
    "retro_file = Path(\"retro_tmp.txt\")\n",
    "if retro_file.is_file(): \n",
    "    for smiles in unique_smiles:\n",
    "        if not smiles in open('retro_tmp.txt').read():\n",
    "            filtered_smiles.append(smiles)\n",
    "else:\n",
    "    filtered_smiles = unique_smiles\n",
    "print(len(filtered_smiles))\n",
    "working_q = mp.Queue()\n",
    "output_q = mp.Queue()\n",
    "for f_smiles in filtered_smiles:\n",
    "    working_q.put(f_smiles)\n",
    "processes = [mp.Process(target=worker,args=(working_q, output_q)) for i in range(mp.cpu_count())]\n",
    "for proc in processes:\n",
    "    proc.start()\n",
    "for proc in processes:\n",
    "    proc.join()\n",
    "with open(\"retro_tmp.txt\", \"a+\") as f_object:\n",
    "    while True:\n",
    "        if output_q.empty() == True:\n",
    "            break\n",
    "        f_object.write(output_q.get_nowait())\n",
    "f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7322d319-992a-48ff-9372-ea87e6940592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1cc(Nc2ccc(C#N)cc2)[nH]n1</td>\n",
       "      <td>['Cc1cc(N)[nH]n1', 'Cc1cc(Cl)[nH]n1', 'Cc1cc(N...</td>\n",
       "      <td>['N#Cc1ccc(B(O)O)cc1', 'N#Cc1ccc(N)cc1', 'N#Cc...</td>\n",
       "      <td>[0.999052584, 0.999052584, 0.999052584]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCOc1ccc(Nc2cc(C)n[nH]2)cc1</td>\n",
       "      <td>['CCOc1ccc(Br)cc1']</td>\n",
       "      <td>['Cc1cc(N)[nH]n1']</td>\n",
       "      <td>[0.911036551]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1cc(Nc2c[nH]nc2C)[nH]n1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COc1ncccc1Nc1cc(C)n[nH]1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1cc(Nc2cccc(S(C)(=O)=O)c2)[nH]n1</td>\n",
       "      <td>['CS(=O)(=O)c1cccc(B(O)O)c1', 'CS(=O)(=O)c1ccc...</td>\n",
       "      <td>['Cc1cc(N)[nH]n1', 'Cc1cc(N)[nH]n1']</td>\n",
       "      <td>[0.996350527, 0.996350527]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>CCOc1ccccc1-c1ccnc(CO)c1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>CNC(=O)c1ccccc1-c1ccnc(CO)c1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>OCc1cc(-c2cc[nH]n2)ccn1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>OCc1cc(-c2ccnc3ccccc23)ccn1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>OCc1cc(Cc2cc(F)cc(F)c2)ccn1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6045 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0  \\\n",
       "0            Cc1cc(Nc2ccc(C#N)cc2)[nH]n1   \n",
       "1            CCOc1ccc(Nc2cc(C)n[nH]2)cc1   \n",
       "2              Cc1cc(Nc2c[nH]nc2C)[nH]n1   \n",
       "3               COc1ncccc1Nc1cc(C)n[nH]1   \n",
       "4     Cc1cc(Nc2cccc(S(C)(=O)=O)c2)[nH]n1   \n",
       "...                                  ...   \n",
       "6040            CCOc1ccccc1-c1ccnc(CO)c1   \n",
       "6041        CNC(=O)c1ccccc1-c1ccnc(CO)c1   \n",
       "6042             OCc1cc(-c2cc[nH]n2)ccn1   \n",
       "6043         OCc1cc(-c2ccnc3ccccc23)ccn1   \n",
       "6044         OCc1cc(Cc2cc(F)cc(F)c2)ccn1   \n",
       "\n",
       "                                                      1  \\\n",
       "0     ['Cc1cc(N)[nH]n1', 'Cc1cc(Cl)[nH]n1', 'Cc1cc(N...   \n",
       "1                                   ['CCOc1ccc(Br)cc1']   \n",
       "2                                                [None]   \n",
       "3                                                [None]   \n",
       "4     ['CS(=O)(=O)c1cccc(B(O)O)c1', 'CS(=O)(=O)c1ccc...   \n",
       "...                                                 ...   \n",
       "6040                                             [None]   \n",
       "6041                                             [None]   \n",
       "6042                                             [None]   \n",
       "6043                                             [None]   \n",
       "6044                                             [None]   \n",
       "\n",
       "                                                      2  \\\n",
       "0     ['N#Cc1ccc(B(O)O)cc1', 'N#Cc1ccc(N)cc1', 'N#Cc...   \n",
       "1                                    ['Cc1cc(N)[nH]n1']   \n",
       "2                                                [None]   \n",
       "3                                                [None]   \n",
       "4                  ['Cc1cc(N)[nH]n1', 'Cc1cc(N)[nH]n1']   \n",
       "...                                                 ...   \n",
       "6040                                             [None]   \n",
       "6041                                             [None]   \n",
       "6042                                             [None]   \n",
       "6043                                             [None]   \n",
       "6044                                             [None]   \n",
       "\n",
       "                                            3  \n",
       "0     [0.999052584, 0.999052584, 0.999052584]  \n",
       "1                               [0.911036551]  \n",
       "2                                         [0]  \n",
       "3                                         [0]  \n",
       "4                  [0.996350527, 0.996350527]  \n",
       "...                                       ...  \n",
       "6040                                      [0]  \n",
       "6041                                      [0]  \n",
       "6042                                      [0]  \n",
       "6043                                      [0]  \n",
       "6044                                      [0]  \n",
       "\n",
       "[6045 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retro_data = pd.read_csv('retro.txt', sep=\"; \", header=None)\n",
    "# retro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ec44e-7edc-43d5-9222-18a6a28fbdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
